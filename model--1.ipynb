{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'bat_charge(4).csv'  # Update this to your file path\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Time' column to datetime format\n",
    "data['Time'] = pd.to_datetime(data['Time'], format='%d-%m-%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>VDC</th>\n",
       "      <th>Isp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-07 22:30:00</td>\n",
       "      <td>363.616943</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-07 22:31:00</td>\n",
       "      <td>365.859985</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-07 22:31:00</td>\n",
       "      <td>366.348267</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-07 22:31:00</td>\n",
       "      <td>366.683960</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-07 22:31:00</td>\n",
       "      <td>366.943359</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>2022-06-07 06:33:00</td>\n",
       "      <td>360.046387</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>2022-06-07 06:33:00</td>\n",
       "      <td>360.031128</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>2022-06-07 06:33:00</td>\n",
       "      <td>360.031128</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>2022-06-07 06:33:00</td>\n",
       "      <td>360.015869</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>2022-06-07 06:33:00</td>\n",
       "      <td>360.000610</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2880 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Time         VDC  Isp\n",
       "0    2022-05-07 22:30:00  363.616943   10\n",
       "1    2022-05-07 22:31:00  365.859985   10\n",
       "2    2022-05-07 22:31:00  366.348267   10\n",
       "3    2022-05-07 22:31:00  366.683960   10\n",
       "4    2022-05-07 22:31:00  366.943359   10\n",
       "...                  ...         ...  ...\n",
       "2875 2022-06-07 06:33:00  360.046387   10\n",
       "2876 2022-06-07 06:33:00  360.031128   10\n",
       "2877 2022-06-07 06:33:00  360.031128   10\n",
       "2878 2022-06-07 06:33:00  360.015869   10\n",
       "2879 2022-06-07 06:33:00  360.000610   10\n",
       "\n",
       "[2880 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'Time' as the index\n",
    "data.set_index('Time', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\0931\\AppData\\Local\\Temp\\ipykernel_14580\\3366766124.py:2: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  data = data.resample('T').mean().interpolate()  # Resampling per minute and interpolating missing values\n"
     ]
    }
   ],
   "source": [
    "# Resample the data if needed (assuming 1-minute intervals)\n",
    "data = data.resample('T').mean().interpolate()  # Resampling per minute and interpolating missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VDC</th>\n",
       "      <th>Isp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-07 22:30:00</th>\n",
       "      <td>363.616943</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-07 22:31:00</th>\n",
       "      <td>366.727193</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-07 22:32:00</th>\n",
       "      <td>367.904663</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-07 22:33:00</th>\n",
       "      <td>368.682862</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-07 22:34:00</th>\n",
       "      <td>369.328817</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-07 06:29:00</th>\n",
       "      <td>360.115051</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-07 06:30:00</th>\n",
       "      <td>360.084534</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-07 06:31:00</th>\n",
       "      <td>360.074361</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-07 06:32:00</th>\n",
       "      <td>360.056559</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-07 06:33:00</th>\n",
       "      <td>360.025024</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43684 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            VDC   Isp\n",
       "Time                                 \n",
       "2022-05-07 22:30:00  363.616943  10.0\n",
       "2022-05-07 22:31:00  366.727193  10.0\n",
       "2022-05-07 22:32:00  367.904663  10.0\n",
       "2022-05-07 22:33:00  368.682862  10.0\n",
       "2022-05-07 22:34:00  369.328817  10.0\n",
       "...                         ...   ...\n",
       "2022-06-07 06:29:00  360.115051  10.0\n",
       "2022-06-07 06:30:00  360.084534  10.0\n",
       "2022-06-07 06:31:00  360.074361  10.0\n",
       "2022-06-07 06:32:00  360.056559  10.0\n",
       "2022-06-07 06:33:00  360.025024  10.0\n",
       "\n",
       "[43684 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the 'VDC' column\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data['VDC_normalized'] = scaler.fit_transform(data['VDC'].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for LSTM\n",
    "def create_sequences(data, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - n_steps):\n",
    "        X.append(data[i:i + n_steps, 0])\n",
    "        y.append(data[i + n_steps, 0])\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the normalized VDC for modeling\n",
    "sequence_data = data['VDC_normalized'].values.reshape(-1, 1)\n",
    "n_steps = 30  # Number of time steps to look back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences\n",
    "X, y = create_sequences(sequence_data, n_steps)\n",
    "\n",
    "# Reshape X for LSTM [samples, time steps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\0931\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 0.0344 - val_loss: 1.3318e-06\n",
      "Epoch 2/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 8.7360e-07 - val_loss: 2.6665e-06\n",
      "Epoch 3/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 1.5547e-06 - val_loss: 1.0129e-06\n",
      "Epoch 4/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 1.1867e-06 - val_loss: 1.8884e-06\n",
      "Epoch 5/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 2.0175e-06 - val_loss: 3.1581e-06\n",
      "Epoch 6/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 5.7077e-06 - val_loss: 4.7226e-07\n",
      "Epoch 7/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 2.1617e-06 - val_loss: 2.0205e-06\n",
      "Epoch 8/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 2.1167e-05 - val_loss: 2.5108e-06\n",
      "Epoch 9/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 1.0819e-06 - val_loss: 2.9969e-07\n",
      "Epoch 10/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 6.1884e-06 - val_loss: 3.1423e-07\n",
      "Epoch 11/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 2.2596e-06 - val_loss: 1.8250e-06\n",
      "Epoch 12/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 9.8757e-07 - val_loss: 4.2564e-07\n",
      "Epoch 13/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 1.9354e-06 - val_loss: 1.4504e-07\n",
      "Epoch 14/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 1.4702e-06 - val_loss: 2.9927e-07\n",
      "Epoch 15/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 7.3477e-07 - val_loss: 4.8002e-07\n",
      "Epoch 16/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 1.4691e-06 - val_loss: 1.9523e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 1.3578e-06 - val_loss: 3.5002e-06\n",
      "Epoch 18/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 1.1177e-06 - val_loss: 1.6027e-07\n",
      "Epoch 19/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 7.4803e-07 - val_loss: 6.9251e-07\n",
      "Epoch 20/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 9.9631e-07 - val_loss: 1.1368e-06\n",
      "Epoch 21/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 6.8030e-07 - val_loss: 1.5552e-06\n",
      "Epoch 22/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 1.1033e-06 - val_loss: 2.2387e-06\n",
      "Epoch 23/100\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 8.8055e-07 - val_loss: 2.9328e-07\n"
     ]
    }
   ],
   "source": [
    "# Early stopping to avoid overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, callbacks=[early_stopping], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('lstm_vdc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2099e-07\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse normalization to get actual VDC values\n",
    "y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "y_pred_actual = scaler.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.2404363970319708e-05\n",
      "MAE: 0.0026843348914590754\n",
      "R^2: 0.9998667004762997\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test_actual, y_pred_actual)\n",
    "mae = mean_absolute_error(y_test_actual, y_pred_actual)\n",
    "r2 = r2_score(y_test_actual, y_pred_actual)\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'R^2: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "[[360.07632]\n",
      " [360.06653]\n",
      " [360.05743]\n",
      " [360.04907]\n",
      " [360.0414 ]\n",
      " [360.03424]\n",
      " [360.02756]\n",
      " [360.02127]\n",
      " [360.01538]\n",
      " [360.00977]\n",
      " [360.00446]\n",
      " [359.99945]\n",
      " [359.99463]\n",
      " [359.99008]\n",
      " [359.98575]\n",
      " [359.98163]\n",
      " [359.97766]\n",
      " [359.97388]\n",
      " [359.97037]\n",
      " [359.9671 ]\n",
      " [359.96408]\n",
      " [359.9613 ]\n",
      " [359.95868]\n",
      " [359.9562 ]\n",
      " [359.95386]\n",
      " [359.9517 ]\n",
      " [359.94965]\n",
      " [359.94772]\n",
      " [359.9459 ]\n",
      " [359.94415]\n",
      " [359.94254]\n",
      " [359.94098]\n",
      " [359.9395 ]\n",
      " [359.93817]\n",
      " [359.93686]\n",
      " [359.93567]\n",
      " [359.93454]\n",
      " [359.93344]\n",
      " [359.93243]\n",
      " [359.9315 ]\n",
      " [359.9306 ]\n",
      " [359.92975]\n",
      " [359.92896]\n",
      " [359.9282 ]\n",
      " [359.92752]\n",
      " [359.92685]\n",
      " [359.9262 ]\n",
      " [359.92563]\n",
      " [359.92508]\n",
      " [359.92456]\n",
      " [359.92404]\n",
      " [359.9236 ]\n",
      " [359.92316]\n",
      " [359.92276]\n",
      " [359.92236]\n",
      " [359.92203]\n",
      " [359.92166]\n",
      " [359.92133]\n",
      " [359.92105]\n",
      " [359.92075]\n",
      " [359.92047]\n",
      " [359.92023]\n",
      " [359.91998]\n",
      " [359.91977]\n",
      " [359.91956]\n",
      " [359.91937]\n",
      " [359.91916]\n",
      " [359.91898]\n",
      " [359.91882]\n",
      " [359.91867]\n",
      " [359.91852]\n",
      " [359.91837]\n",
      " [359.91824]\n",
      " [359.91812]\n",
      " [359.918  ]\n",
      " [359.91788]\n",
      " [359.9178 ]\n",
      " [359.9177 ]\n",
      " [359.9176 ]\n",
      " [359.9175 ]\n",
      " [359.91745]\n",
      " [359.91736]\n",
      " [359.91727]\n",
      " [359.91724]\n",
      " [359.91714]\n",
      " [359.91708]\n",
      " [359.91702]\n",
      " [359.917  ]\n",
      " [359.91693]\n",
      " [359.9169 ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Predict the next 90 minutes\n",
    "last_sequence = data['VDC_normalized'].values[-n_steps:]\n",
    "predictions = []\n",
    "\n",
    "for _ in range(90):\n",
    "    next_pred = model.predict(last_sequence.reshape(1, n_steps, 1))\n",
    "    predictions.append(next_pred[0, 0])\n",
    "    last_sequence = np.append(last_sequence[1:], next_pred)\n",
    "\n",
    "# Reverse normalization to get actual VDC predictions\n",
    "predictions_actual = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
    "\n",
    "print(predictions_actual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\0931\\AppData\\Local\\Temp\\ipykernel_14580\\816796782.py:22: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  data = data.resample('T').mean().interpolate()  # Resampling per minute and interpolating missing values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted VDC values for the next 23 minutes:\n",
      "[[360.07632]\n",
      " [360.06653]\n",
      " [360.05743]\n",
      " [360.04907]\n",
      " [360.0414 ]\n",
      " [360.03424]\n",
      " [360.02756]\n",
      " [360.02127]\n",
      " [360.01538]\n",
      " [360.00977]\n",
      " [360.00446]\n",
      " [359.99945]\n",
      " [359.99463]\n",
      " [359.99008]\n",
      " [359.98575]\n",
      " [359.98163]\n",
      " [359.97766]\n",
      " [359.97388]\n",
      " [359.97037]\n",
      " [359.9671 ]\n",
      " [359.96408]\n",
      " [359.9613 ]\n",
      " [359.95868]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('lstm_vdc_model.h5', compile=False)\n",
    "model.compile(optimizer='adam', loss=MeanSquaredError())\n",
    "\n",
    "# Load the dataset to get the last sequence of data\n",
    "file_path = 'bat_charge(4).csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert the 'Time' column to datetime format\n",
    "data['Time'] = pd.to_datetime(data['Time'], format='%d-%m-%Y %H:%M')\n",
    "\n",
    "# Set 'Time' as the index\n",
    "data.set_index('Time', inplace=True)\n",
    "\n",
    "# Resample the data if needed (assuming 1-minute intervals)\n",
    "data = data.resample('T').mean().interpolate()  # Resampling per minute and interpolating missing values\n",
    "\n",
    "# Normalize the 'VDC' column\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data['VDC_normalized'] = scaler.fit_transform(data['VDC'].values.reshape(-1, 1))\n",
    "\n",
    "# Prepare the last sequence of data\n",
    "n_steps = 30  # Number of time steps to look back\n",
    "last_sequence = data['VDC_normalized'].values[-n_steps:]\n",
    "\n",
    "# Function to predict VDC for the next n minutes\n",
    "def predict_future_vdc(minutes):\n",
    "    predictions = []\n",
    "    sequence = last_sequence.copy()\n",
    "    \n",
    "    for _ in range(minutes):\n",
    "        next_pred = model.predict(sequence.reshape(1, n_steps, 1))\n",
    "        predictions.append(next_pred[0, 0])\n",
    "        sequence = np.append(sequence[1:], next_pred)\n",
    "    \n",
    "    # Reverse normalization to get actual VDC predictions\n",
    "    predictions_actual = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
    "    \n",
    "    return predictions_actual\n",
    "\n",
    "# User input for the number of minutes\n",
    "minutes = int(input(\"Enter the number of minutes to predict the VDC for: \"))\n",
    "\n",
    "# Make the prediction\n",
    "predicted_values = predict_future_vdc(minutes)\n",
    "\n",
    "# Display the predicted values\n",
    "print(f\"Predicted VDC values for the next {minutes} minutes:\")\n",
    "print(predicted_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'bat_charge(4).csv'  # Update this to your file path\n",
    "data = pd.read_csv(file_path)\n",
    "data['Time'] = pd.to_datetime(data['Time'], format='%d-%m-%Y %H:%M')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'Time' as the index\n",
    "data.set_index('Time', inplace=True)\n",
    "# Resample the data if needed (assuming 1-minute intervals)\n",
    "data = data.resample('T').mean().interpolate()  # Resampling per minute and interpolating missing values\n",
    "\n",
    "# Normalize the 'VDC' column\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data['VDC_normalized'] = scaler.fit_transform(data['VDC'].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for DNN\n",
    "def create_sequences(data, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - n_steps):\n",
    "        X.append(data[i:i + n_steps, 0])\n",
    "        y.append(data[i + n_steps, 0])\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the normalized VDC for modeling\n",
    "sequence_data = data['VDC_normalized'].values.reshape(-1, 1)\n",
    "n_steps = 30  # Number of time steps to look back\n",
    "# Create sequences\n",
    "X, y = create_sequences(sequence_data, n_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1092/1092 [==============================] - 2s 1ms/step - loss: 0.0018 - val_loss: 1.4456e-06\n",
      "Epoch 2/100\n",
      "1092/1092 [==============================] - 1s 1ms/step - loss: 9.1323e-07 - val_loss: 9.0515e-07\n",
      "Epoch 3/100\n",
      "1092/1092 [==============================] - 1s 1ms/step - loss: 8.7182e-07 - val_loss: 7.8745e-07\n",
      "Epoch 4/100\n",
      "1092/1092 [==============================] - 1s 1ms/step - loss: 9.8369e-07 - val_loss: 1.6482e-06\n",
      "Epoch 5/100\n",
      "1092/1092 [==============================] - 1s 1ms/step - loss: 1.2372e-06 - val_loss: 1.5776e-06\n",
      "Epoch 6/100\n",
      "1092/1092 [==============================] - 1s 1ms/step - loss: 2.1774e-06 - val_loss: 7.4005e-07\n",
      "Epoch 7/100\n",
      "1092/1092 [==============================] - 1s 1ms/step - loss: 2.2847e-06 - val_loss: 1.1369e-05\n",
      "Epoch 8/100\n",
      "1092/1092 [==============================] - 1s 981us/step - loss: 8.6072e-06 - val_loss: 6.5726e-06\n",
      "Epoch 9/100\n",
      "1092/1092 [==============================] - 1s 1ms/step - loss: 4.6092e-06 - val_loss: 1.5039e-06\n",
      "Epoch 10/100\n",
      "1092/1092 [==============================] - 1s 1ms/step - loss: 3.2779e-06 - val_loss: 1.2875e-05\n",
      "Epoch 11/100\n",
      "1092/1092 [==============================] - 2s 1ms/step - loss: 3.4402e-06 - val_loss: 1.0682e-06\n",
      "Epoch 12/100\n",
      "1092/1092 [==============================] - 1s 1ms/step - loss: 2.8656e-06 - val_loss: 1.0228e-06\n",
      "Epoch 13/100\n",
      "1092/1092 [==============================] - 1s 1ms/step - loss: 3.1569e-06 - val_loss: 3.4154e-06\n",
      "Epoch 14/100\n",
      "1092/1092 [==============================] - 1s 1ms/step - loss: 2.9981e-06 - val_loss: 5.6621e-06\n",
      "Epoch 15/100\n",
      "1092/1092 [==============================] - 1s 1ms/step - loss: 1.9911e-06 - val_loss: 9.2494e-07\n",
      "Epoch 16/100\n",
      "1092/1092 [==============================] - 1s 1ms/step - loss: 2.0895e-06 - val_loss: 3.7091e-06\n"
     ]
    }
   ],
   "source": [
    "# Define the DNN model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=n_steps))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# Early stopping to avoid overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, callbacks=[early_stopping], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\0871\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('dnn_vdc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 [==============================] - 0s 691us/step - loss: 7.4005e-07\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 [==============================] - 0s 853us/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "# Reverse normalization to get actual VDC values\n",
    "y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "y_pred_actual = scaler.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00011431875252605193\n",
      "MAE: 0.007846188713017552\n",
      "R^2: 0.9993198362925221\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test_actual, y_pred_actual)\n",
    "mae = mean_absolute_error(y_test_actual, y_pred_actual)\n",
    "r2 = r2_score(y_test_actual, y_pred_actual)\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'R^2: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Predicted VDC values for the next 10 minutes:\n",
      "[[360.07254]\n",
      " [360.06406]\n",
      " [360.0637 ]\n",
      " [360.0554 ]\n",
      " [360.0332 ]\n",
      " [360.02548]\n",
      " [360.01883]\n",
      " [360.02216]\n",
      " [360.01657]\n",
      " [360.01828]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the saved model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('dnn_vdc_model.h5')\n",
    "\n",
    "# Load the dataset to get the last sequence of data\n",
    "data = pd.read_csv(file_path)\n",
    "data['Time'] = pd.to_datetime(data['Time'], format='%d-%m-%Y %H:%M')\n",
    "data.set_index('Time', inplace=True)\n",
    "data = data.resample('T').mean().interpolate()  # Resampling per minute and interpolating missing values\n",
    "\n",
    "# Normalize the 'VDC' column\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data['VDC_normalized'] = scaler.fit_transform(data['VDC'].values.reshape(-1, 1))\n",
    "\n",
    "# Prepare the last sequence of data\n",
    "last_sequence = data['VDC_normalized'].values[-n_steps:]\n",
    "\n",
    "# Function to predict VDC for the next n minutes\n",
    "def predict_future_vdc(minutes):\n",
    "    predictions = []\n",
    "    sequence = last_sequence.copy()\n",
    "    \n",
    "    for _ in range(minutes):\n",
    "        next_pred = model.predict(sequence.reshape(1, n_steps))\n",
    "        predictions.append(next_pred[0, 0])\n",
    "        sequence = np.append(sequence[1:], next_pred)\n",
    "    \n",
    "    # Reverse normalization to get actual VDC predictions\n",
    "    predictions_actual = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
    "    \n",
    "    return predictions_actual\n",
    "\n",
    "# User input for the number of minutes\n",
    "minutes = int(input(\"Enter the number of minutes to predict the VDC for: \"))\n",
    "\n",
    "# Make the prediction\n",
    "predicted_values = predict_future_vdc(minutes)\n",
    "\n",
    "# Display the predicted values\n",
    "print(f\"Predicted VDC values for the next {minutes} minutes:\")\n",
    "print(predicted_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
